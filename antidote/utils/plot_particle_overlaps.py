"""
Parses two files containing particle coordinates and micrograph names in order to determine which particles are
shared between the two files. This can be useful for characterizing Antidote's performance and analyzing the
behavior of cryoSPARC-, RELION-, or Antidote-based processing approaches.

Args:
-   path1 (pathlib.Path): The path to the first input file in either cryoSPARC or RELION STAR format.
-   path2 (pathlib.Path): The path to the second input file n either cryoSPARC or RELION STAR format.
-   output (pathlib.Path): The path to which the output png file will be written.
-   atol (int): A value representing the maximum distance (in pixels) for calling a match condition. If this
                value is less than or equal to 0, a fast vectorized approach to finding matches will be run.

Returns:
-   None. For now, this just writes a Venn plot to the output path. This function can be updated to return a
    dataframe if this is valuable.

Limitations:
Parsing of the micrograph name expects the format generated by EPU-based micrograph acquisition approaches,
specifically a series of four integers separated by underscores. See the get_micrograph_id_from_path_str()
function for more information.
"""

import concurrent.futures
from collections import defaultdict
import logging
import matplotlib.pyplot as plt
from matplotlib_venn import venn2
import numpy as np
import pandas as pd
import re
import starfile
import sys
from tqdm import tqdm

logger = logging.getLogger(__name__)


def batch_executor_for_hashes(mic, group, atol):
    """
    Identify coordinate matches within an input dataframe and add them to a dictionary of sets.

    Args:
    -   mic (str): micrograph ID
    -   group (pd.DataFrame): A dataframe generated by a groupby operation on the dataframe
                              representing all of the particle locations
    -   atol (int): an integer representing the tolerance allowed for the match condition

    Returns:
    -   hash_dict_local (defaulttdict): A dictionary where each key is the 'source' (i.e. the
                                        filename of the input) and each value is a set object
                                        containing unique hashes of micrograph ids + particle
                                        coordinates. Matched coordinates (that fall within atol
                                        and have the same micrograph id) evaluate to the same
                                        hash.
    """
    hash_dict_local = defaultdict(set)

    for i in range(len(group)):
        for j in range(i + 1, len(group)):
            # create a few variables for ease of interaction with groupby object
            x1, y1 = (
                group["rlnCoordinateX"].iloc[i],
                group["rlnCoordinateY"].iloc[i],
            )
            x2, y2 = (
                group["rlnCoordinateX"].iloc[j],
                group["rlnCoordinateY"].iloc[j],
            )
            srci = group["source"].iloc[i]
            srcj = group["source"].iloc[j]

            # If they're close based on the given tolerance, add to the list
            if np.isclose(x1, x2, atol=atol) and np.isclose(y1, y2, atol=atol):
                # this will evaluate to the same hash for every match regardless of order
                xmax, ymax = max(x1, x2), max(y1, y2)
                data = f"{mic}-{xmax}-{ymax}"
                data_hash = hash(data)
                hash_dict_local[srci].add(data_hash)
                hash_dict_local[srcj].add(data_hash)
            else:
                hash_dict_local[srci].add(hash(f"{mic}-{x1}-{y1}"))
                hash_dict_local[srcj].add(hash(f"{mic}-{x2}-{y2}"))

    return hash_dict_local


def hash_matches(df, atol):
    """
    Returns a dict of hashes for input micrographs using the batch_executor method
    """

    hash_dict = defaultdict(set)
    total_mics = df["mic_id"].nunique()

    # sends groupby objects (representing micrographs) off to batch_executor()
    with concurrent.futures.ProcessPoolExecutor(max_workers=None) as executor:
        futures = [executor.submit(batch_executor_for_hashes, mic, group, atol) for mic, group in df.groupby(["mic_id"])]

        for _, future in enumerate(
            tqdm(
                concurrent.futures.as_completed(futures),
                total=total_mics,
                desc="Processing micrographs",
            )
        ):
            hash_dict_local = future.result()
            for k, v in hash_dict_local.items():
                hash_dict[k].update(v)

    return hash_dict


def hash_exact_matches(df):
    """
    Returns a dict of hashes for input micrographs using a vectorized approach that only works for exact matches.
    """

    df["rlnCoordinateX"] = df["rlnCoordinateX"].round().astype(int)
    df["rlnCoordinateY"] = df["rlnCoordinateY"].round().astype(int)

    # hashing is probably not even necessary here
    df["ptcl_hash"] = pd.util.hash_pandas_object(
        df["rlnCoordinateX"].astype(str) + "_" + df["rlnCoordinateY"].astype(str) + "_" + df["mic_id"].astype(str),
        index=False,
    )

    hash_dict = df.groupby("source")["ptcl_hash"].apply(set).to_dict()

    return hash_dict


def get_micrograph_id_from_path_str(path):
    """
    Takes a path or string and pattern matches to find the 4-digit micrograph ID
    """
    # convert input to str
    if not isinstance(path, str):
        path = str(path)

    pattern = r"(\d+)_(\d+)_(\d+)_(\d+)"
    match = re.search(pattern, path)

    if match:
        return "_".join(match.groups())
    else:
        logger.error("No 4-digit match found")


def parse_starfile(path, munged=True):
    """
    Takes the path to a relion starfile and returns a munged dataframe
    """

    starfile_od = starfile.read(path)
    df = starfile_od["particles"].copy()  # may cause memory issues

    if munged:
        df = df[["rlnImageName", "rlnCoordinateX", "rlnCoordinateY"]]
        df["mic_id"] = df["rlnImageName"].apply(lambda x: get_micrograph_id_from_path_str(x))
        df["source"] = f"{path.name}"
        return df
    else:
        return df


def parse_csfile(path, munged=True):
    """
    Takes the path to a cryoSPARC cs file and returns a munged dataframe
    """

    data = np.load(path)
    df = pd.DataFrame.from_records(data.tolist(), columns=data.dtype.names).copy()  # may cause memory issue

    if munged:
        df = df[
            [
                "location/micrograph_path",
                "location/micrograph_shape",
                "location/center_x_frac",
                "location/center_y_frac",
            ]
        ]
        data_xloc = df["location/micrograph_shape"][0][0] * df["location/center_x_frac"]
        data_yloc = df["location/micrograph_shape"][0][1] * df["location/center_y_frac"]
        image_name = df["location/micrograph_path"]

        # regenerate relion-like df from parsed cs df
        data_xloc.name = "rlnCoordinateX"  # Use RELION's naming convention
        data_yloc.name = "rlnCoordinateY"
        image_name.name = "rlnImageName"
        df = pd.concat([image_name, data_xloc.round(), data_yloc.round()], axis=1)

        df["mic_id"] = df["rlnImageName"].apply(lambda x: get_micrograph_id_from_path_str(x))
        df["source"] = f"{path.name}"
        return df
    else:
        return df


def parse_path(path):
    """
    Send file defined in input path to appropriate parser and exit gracefully if no parser is available.
    """
    if path.suffix == ".star":
        parsed_df = parse_starfile(path)
    elif path.suffix == ".cs":
        parsed_df = parse_csfile(path)
    else:
        logger.fatal("Only STAR and cryoSPARC files are supported.")
        logger.fatal("Exiting...")
        sys.exit()

    return parsed_df


def plot_venn(path1, path2, hashes, output, atol):
    """
    Plot a venn diagram of particle overlaps.
    """

    # Create a Venn diagram with two sets
    venn = venn2(
        [hashes[f"{path1.name}"], hashes[f"{path2.name}"]],
        (f"{path1.name}, {path2.name}"),
    )

    # Customize the labels and title
    venn.get_label_by_id("10")
    venn.get_label_by_id("01")
    venn.get_label_by_id("11")

    plt.title(f"Overlap for {path1.name} and {path2.name}, tolerance = {atol} px")

    plt.savefig(output)


def run(path1, path2, output, atol):
    """
    Run the particle overlap plotting script.
    """

    df1, df2 = parse_path(path1), parse_path(path2)

    if atol <= 0:
        # exact matches only
        hashes = hash_exact_matches(pd.concat([df1, df2], ignore_index=True))
    else:
        # generate unique hashes for all particles in both input files
        hashes = hash_matches(pd.concat([df1, df2], ignore_index=True), atol=atol)

    plot_venn(path1, path2, hashes, output, atol)


if __name__ == "__main__":
    pass
